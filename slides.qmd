---
title: "Principal Component Analysis"
format: revealjs
editor: visual
author: Andrew Mercer, Curtis Fox, Eddie Pierce
---

## Intoduction
* Principal Component Analysis (PCA) is a widely used statistical method for reducing the dimensionality of multivariate data.

* The goal is to transform the original variables into a new set of uncorrelated variables called principal components.

* The Principal Components are used in place of the original variables to reduce data dimensionality to find more accurate results and identify the most important factors that contribute to overall performance.

## How It Works in Simple Terms
* The data is plotted along a normal x and y graph. The average distance to each axis is used to find the center of the data. The center is then shifted to the origin.

* PC1 is the line that is fitted to the shifted data through the origin using the maximum sum of squared distances it calculated. PC2 is then found by creating a scaled perpendicular line to the fitted line through the origin. The lines are rotated to the axis.

* The linear combination of the slope of each line is used to find the eigenvalues and eigenvectors. The proportion of each variable used to create the line is the loading score.


## What You Need for PCA

* Your data needs to be Numeric.

* Multiple variables, 4 or more.

* A general understanding of your data and variables.

## Literature Review
* PCA has been applied in various fields such as remote sensing, public health, finance, sports, and climate analysis.

* Watnik, Mitchell, and Richard A Levine. 2001. “NFL Y2K PCA.” Journal of Statistics Education 9 (3).

* Jones, Lewis. 2016. “Modeling NFL Quarterback Success with College Data.” PhD thesis, University of Georgia.

* We found a shared interest in individual Quarterback performance across the National Football League. The data was numeric with multiple variables and we had a strong understanding of the data. 

## Methods

## Methods

## Data

## Correlation Matrix
```{r}
our_data = read.csv("NFL_Data.csv")
library('ggplot2')
library('corrr')
library('ggcorrplot')
library('FactoMineR')
library('factoextra')
our_data[is.na(our_data)] = 0
numerical_data = our_data[,2:51]
data_normalized = scale(numerical_data)
corr_matrix = cor(data_normalized)
ggcorrplot(corr_matrix, tl.cex = 5,tl.srt = 45)

```



## Scree Plot
*
```{r}
data.pca = princomp(corr_matrix)
fviz_eig(data.pca, addlabels = TRUE) #this is a scree plot of the principal component

```

## Biplot
*
```{r}
fviz_pca_biplot(data.pca,
geom.ind="point",
col.ind="black",
pointshape=16,pointsize=2,
mean.point=FALSE,
alpha.var="contrib",col.var="cos2",
gradient.cols=c("#00AFBB","#E7B800","#FC4E07"),
labelsize=3,
repel=TRUE,
xlab="PC 1",
ylab="PC 2")
```

## Biplot 2
*
```{r}
fviz_pca_var(data.pca, col.var = "black")

```

## Cos2 Graph
*
```{r}
fviz_cos2(data.pca, choice = "var",axes = 1:2)

```

## Combination BiPlot
*
```{r}
fviz_pca_var(data.pca, col.var = "cos2",
            gradient.cols = c("goldenrod1", "indianred",  "cornflowerblue"),
            repel = TRUE)

```

## Conclusion
* 
